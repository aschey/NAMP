<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta httpEquiv="Content-Security-Policy" content="default-src 'self' 'blob'; style-src 'self'; script-src 'self';"/>
    <meta
      name="description"
      content="NAMP"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
    <title>React App</title>
  </head>
  <body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.1.3/howler.core.min.js"></script>
    <script>
      function findStartGapDuration(audioBuffer) {
        // Get the raw audio data for the left & right channels.
        const l = audioBuffer.getChannelData(0);
        const r = audioBuffer.getChannelData(1);
        // Each is an array of numbers between -1 and 1 describing
        // the waveform, sample by sample.

        // Now to figure out how long both channels remain at 0:
        for (let i = 0; i < l.length; i++) {
          if (l[i] || r[i]) {
            // Now we know which sample is non-zero, but we want
            // the gap in seconds, not samples. Thankfully sampleRate
            // gives us the number of samples per second.
            return i / audioBuffer.sampleRate;
          }
        }

        // Hmm, the clip is entirely silent
        return audioBuffer.duration;
      }

      function ReadInt(buffer) {
        var result = buffer.charCodeAt(0);
        for (var i = 1; i < buffer.length; ++i) {
          result <<= 8;
          result += buffer.charCodeAt(i);
        }
        return result;
      }

      function ParseGaplessData(arrayBuffer) {
        // Gapless data is generally within the first 512 bytes, so limit parsing.
        var byteStr = String.fromCharCode.apply(
            null, new Uint8Array(arrayBuffer.slice(0, 512)));

        var frontPadding = 0, endPadding = 0, realSamples = 0;

        var iTunesDataIndex = byteStr.indexOf('iTunSMPB');
        if (iTunesDataIndex != -1) {
          var frontPaddingIndex = iTunesDataIndex + 34;
          frontPadding = parseInt(byteStr.substr(frontPaddingIndex, 8), 16);

          var endPaddingIndex = frontPaddingIndex + 9;
          endPadding = parseInt(byteStr.substr(endPaddingIndex, 8), 16);

          var sampleCountIndex = endPaddingIndex + 9;
          realSamples = parseInt(byteStr.substr(sampleCountIndex, 16), 16);
        }
        var xingDataIndex = byteStr.indexOf('Xing');
        if (xingDataIndex == -1) xingDataIndex = byteStr.indexOf('Info');
        if (xingDataIndex != -1) {
          // See section 2.3.1 in the link above for the specifics on parsing the Xing
          // frame count.
          var frameCountIndex = xingDataIndex + 8;
          var frameCount = ReadInt(byteStr.substr(frameCountIndex, 4));

          // For Layer3 Version 1 and Layer2 there are 1152 samples per frame.  See
          // section 2.1.5 in the link above for more details.
          var paddedSamples = frameCount * 1152;
        }
        xingDataIndex = byteStr.indexOf('LAME');
        if (xingDataIndex == -1) xingDataIndex = byteStr.indexOf('Lavf');
        if (xingDataIndex != -1) {
          // See http://gabriel.mp3-tech.org/mp3infotag.html#delays for details of
          // how this information is encoded and parsed.
          var gaplessDataIndex = xingDataIndex + 21;
          var gaplessBits = ReadInt(byteStr.substr(gaplessDataIndex, 3));

          // Upper 12 bits are the front padding, lower are the end padding.
          frontPadding = gaplessBits >> 12;
          endPadding = gaplessBits & 0xFFF;
        }

        realSamples = paddedSamples - (frontPadding + endPadding);

        return {
          audioDuration: realSamples,
          frontPaddingDuration: frontPadding
        }
      }

      function findEndGapDuration(audioBuffer) {
        // Get the raw audio data for the left & right channels.
        const l = audioBuffer.getChannelData(0);
        const r = audioBuffer.getChannelData(1);
        // Each is an array of numbers between -1 and 1 describing
        // the waveform, sample by sample.

        // Now to figure out how long both channels remain at 0:
        for (let i = l.length - 1; i >= 0; i--) {
          if (l[i] || r[i]) {
            // Now we know which sample is non-zero, but we want
            // the gap in seconds, not samples. Thankfully sampleRate
            // gives us the number of samples per second.
            return audioBuffer.duration - (i / audioBuffer.sampleRate);
          }
        }

        // Hmm, the clip is entirely silent
        return audioBuffer.duration;
      }
      function test1() {
      const context1 = new AudioContext();
      const context2 = context1;
      // 'file:///home/aschey/windows/shared_files/Music/Between the Buried and Me/Colors/04 Sun of Nothing.m4a'
      // 'file:///home/aschey/windows/shared_files/Music/Between the Buried and Me/Colors/05 Ants of the Sky.m4a'
      // 'file:///home/aschey/windows/shared_files/Music/4 Strings/Believe/01 Intro.m4a'
      // 'file:///home/aschey/windows/shared_files/Music/4 Strings/Believe/02 Take Me Away (Into The Night).m4a'
      // 'file:///home/aschey/windows/shared_files/Music/Bent Knee/Shiny Eyed Babies/Bent Knee - Shiny Eyed Babies - 06 Dead Horse.mp3'
      // 'file:///home/aschey/windows/shared_files/Music/Bent Knee/Shiny Eyed Babies/Bent Knee - Shiny Eyed Babies - 07 Battle Creek.mp3'
      // 'file:///home/aschey/windows/shared_files/Music/Rolo Tomassi/Time Will Die and Love Will Bury It/Rolo Tomassi - Time Will Die And Love Will Bury It - 05 Balancing The Dark.mp3'
      // 'file:///home/aschey/windows/shared_files/Music/Rolo Tomassi/Time Will Die and Love Will Bury It/Rolo Tomassi - Time Will Die And Love Will Bury It - 06 Alma Mater.mp3'
      fetch('file:///home/aschey/windows/shared_files/Music/4 Strings/Believe/01 Intro.m4a')
        .then(response => response.arrayBuffer())
        .then(arrayBuffer => {
          console.log(ParseGaplessData(arrayBuffer));
          return context1.decodeAudioData(arrayBuffer);
        })
        .then(audioBuffer => {
          // Create a source:
          // This represents a playback head.
          const source = context1.createBufferSource();
          // Give it the audio data we loaded:
          source.buffer = audioBuffer;
          // Plug it into the output:
          source.connect(context1.destination);
          // And off we go!
          const s = Math.round(audioBuffer.duration * .95);
          const gap1 = findEndGapDuration(audioBuffer);
          const switchTime = audioBuffer.duration - s;
          source.start(0, s);
          source.stop(switchTime - gap1);
          console.log('start1', 0, s);
          fetch('file:///home/aschey/windows/shared_files/Music/4 Strings/Believe/02 Take Me Away (Into The Night).m4a')
            .then(response => response.arrayBuffer())
            .then(arrayBuffer => {
              console.log(ParseGaplessData(arrayBuffer));
              return context2.decodeAudioData(arrayBuffer);
            })
            .then(audioBuffer2 => {
              // Create a source:
              // This represents a playback head.
              const source2 = context2.createBufferSource();
              // Give it the audio data we loaded:
              source2.buffer = audioBuffer2;
             
              console.log(gap1);
              const gap2 = findStartGapDuration(audioBuffer2);
              console.log(gap2);
              // Plug it into the output:
              source2.connect(context2.destination);
              const safetyBuffer = 0.25;
              
              source2.start(switchTime, gap2);
              console.log('start2', switchTime, gap2);
              
              console.log('stop1', switchTime - gap1);
            });
        });
      }
      window.context = new AudioContext();
      //test1();
    </script>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root"></div>
    <!--
      This HTML file is a template.
      If you open it directly in the browser, you will see an empty page.

      You can add webfonts, meta tags, or analytics to this file.
      The build step will place the bundled scripts into the <body> tag.

      To begin the development, run `npm start` or `yarn start`.
      To create a production bundle, use `npm run build` or `yarn build`.
    -->
  </body>
</html>
